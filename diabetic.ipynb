{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "diabetic.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxTxybSBDuAv"
      },
      "source": [
        "# ***Diabetes Prediction***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZn2R8u7f4VU"
      },
      "source": [
        "#Importing all the needed libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "from patsy import dmatrices\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zibTOEx2oayE"
      },
      "source": [
        "#Uploading the dataset.\n",
        "df=pd.read_csv('/diabetes_data_upload.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSceuzpLbpXz"
      },
      "source": [
        "#summary of the dataset.\n",
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl01udwZpCsr"
      },
      "source": [
        "#checking the missing observations.\n",
        "df.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IP79Gd8rq404"
      },
      "source": [
        "#Exploratory data analysis(EDA)\n",
        "plt.figure(figsize=(14,7))\n",
        "plt.subplot(121)\n",
        "label=[\"positive\",\"Negative\"]\n",
        "df[\"class\"].value_counts().plot.pie(autopct = \"%1.1f%%\",colors = sns.color_palette(\"hot\",2),startangle = 90,labels=label,\n",
        "wedgeprops={\"linewidth\":2,\"edgecolor\":\"k\"},explode=[.1,0],shadow =True,)\n",
        "#plt.legend(labels,loc=\"best\")\n",
        "plt.title(\"Distribution of Target  Variable\")\n",
        "plt.subplot(122)\n",
        "ax = df[\"class\"].value_counts().plot(kind=\"barh\",color=['red','yellow'])\n",
        "for i,j in enumerate(df[\"class\"].value_counts().values):\n",
        "    ax.text(0.1,i,j,weight = \"bold\",fontsize=15)\n",
        "plt.title(\"Count of Target Variable\")\n",
        "plt.show()\n",
        "\n",
        "#Age wise distribution \n",
        "sns.distplot(df['Age'],bins=30)\n",
        "\n",
        "#  Gender wise distribution\n",
        "sns.countplot(df['Gender'],hue=df['class'], data=df)\n",
        "plot_criteria= ['Gender', 'class']\n",
        "cm = sns.light_palette(\"blue\", as_cmap=True)\n",
        "(round(pd.crosstab(df[plot_criteria[0]], df[plot_criteria[1]], normalize='columns') * 100,2)).style.background_gradient(cmap = cm)\n",
        "\n",
        "\n",
        "# Distribution of Polyuria\n",
        "sns.countplot(df['Polyuria'],hue=df['class'], data=df)\n",
        "plot_criteria= ['Polyuria', 'class']\n",
        "cm = sns.light_palette(\"blue\", as_cmap=True)\n",
        "(round(pd.crosstab(df[plot_criteria[0]], df[plot_criteria[1]], normalize='columns') * 100,2)).style.background_gradient(cmap = cm)\n",
        "\n",
        "\n",
        "# Distribution of Polydipsia\n",
        "sns.countplot(df['Polydipsia'],hue=df['class'], data=df)\n",
        "plot_criteria= ['Polydipsia', 'class']\n",
        "cm = sns.light_palette(\"red\", as_cmap=True)\n",
        "(round(pd.crosstab(df[plot_criteria[0]], df[plot_criteria[1]], normalize='columns') * 100,2)).style.background_gradient(cmap = cm)\n",
        "\n",
        "#Distribution of sudden weight loss\n",
        "sns.countplot(df['sudden weight loss'],hue=df['class'], data=df)\n",
        "plot_criteria= ['sudden weight loss', 'class']\n",
        "cm = sns.light_palette(\"blue\", as_cmap=True)\n",
        "(round(pd.crosstab(df[plot_criteria[0]], df[plot_criteria[1]], normalize='columns') * 100,2)).style.background_gradient(cmap = cm)\n",
        "\n",
        "# Distribution of weakness\n",
        "sns.countplot(df['weakness'],hue=df['class'], data=df)\n",
        "plot_criteria= ['weakness', 'class']\n",
        "cm = sns.light_palette(\"blue\", as_cmap=True)\n",
        "(round(pd.crosstab(df[plot_criteria[0]], df[plot_criteria[1]], normalize='columns') * 100,2)).style.background_gradient(cmap = cm)\n",
        "\n",
        "# Distribution of Polyphagia\n",
        "sns.countplot(df['Polyphagia'],hue=df['class'], data=df)\n",
        "plot_criteria= ['Polyphagia', 'class']\n",
        "cm = sns.light_palette(\"red\", as_cmap=True)\n",
        "(round(pd.crosstab(df[plot_criteria[0]], df[plot_criteria[1]], normalize='columns') * 100,2)).style.background_gradient(cmap = cm)\n",
        "\n",
        "# Distribution of Genital thrush\n",
        "sns.countplot(df['Genital thrush'],hue=df['class'], data=df)\n",
        "plot_criteria= ['Genital thrush', 'class']\n",
        "cm = sns.light_palette(\"red\", as_cmap=True)\n",
        "(round(pd.crosstab(df[plot_criteria[0]], df[plot_criteria[1]], normalize='columns') * 100,2)).style.background_gradient(cmap = cm)\n",
        "\n",
        "# Distribution of visual blurring\n",
        "sns.countplot(df['visual blurring'],hue=df['class'], data=df)\n",
        "plot_criteria= ['visual blurring', 'class']\n",
        "cm = sns.light_palette(\"red\", as_cmap=True)\n",
        "(round(pd.crosstab(df[plot_criteria[0]], df[plot_criteria[1]], normalize='columns') * 100,2)).style.background_gradient(cmap = cm)\n",
        "\n",
        "# Distribution of Itching\n",
        "sns.countplot(df['Itching'],hue=df['class'], data=df)\n",
        "plot_criteria= ['Itching', 'class']\n",
        "cm = sns.light_palette(\"red\", as_cmap=True)\n",
        "(round(pd.crosstab(df[plot_criteria[0]], df[plot_criteria[1]], normalize='columns') * 100,2)).style.background_gradient(cmap = cm)\n",
        "\n",
        "# Distribution of Irritability\n",
        "sns.countplot(df['Irritability'],hue=df['class'], data=df)\n",
        "plot_criteria= ['Irritability', 'class']\n",
        "cm = sns.light_palette(\"red\", as_cmap=True)\n",
        "(round(pd.crosstab(df[plot_criteria[0]], df[plot_criteria[1]], normalize='columns') * 100,2)).style.background_gradient(cmap = cm)\n",
        "\n",
        "# Distribution of delayed healing\n",
        "sns.countplot(df['delayed healing'],hue=df['class'], data=df)\n",
        "plot_criteria= ['delayed healing', 'class']\n",
        "cm = sns.light_palette(\"red\", as_cmap=True)\n",
        "(round(pd.crosstab(df[plot_criteria[0]], df[plot_criteria[1]], normalize='columns') * 100,2)).style.background_gradient(cmap = cm)\n",
        "\n",
        "# Distribution of partial paresis\n",
        "sns.countplot(df['partial paresis'],hue=df['class'], data=df)\n",
        "plot_criteria= ['partial paresis', 'class']\n",
        "cm = sns.light_palette(\"red\", as_cmap=True)\n",
        "(round(pd.crosstab(df[plot_criteria[0]], df[plot_criteria[1]], normalize='columns') * 100,2)).style.background_gradient(cmap = cm)\n",
        "\n",
        "# Distribution of muscle stiffness\n",
        "sns.countplot(df['muscle stiffness'],hue=df['class'], data=df)\n",
        "plot_criteria= ['muscle stiffness', 'class']\n",
        "cm = sns.light_palette(\"red\", as_cmap=True)\n",
        "(round(pd.crosstab(df[plot_criteria[0]], df[plot_criteria[1]], normalize='columns') * 100,2)).style.background_gradient(cmap = cm)\n",
        "\n",
        "# Distribution of Alopecia\n",
        "sns.countplot(df['Alopecia'],hue=df['class'], data=df)\n",
        "plot_criteria= ['Alopecia', 'class']\n",
        "cm = sns.light_palette(\"red\", as_cmap=True)\n",
        "(round(pd.crosstab(df[plot_criteria[0]], df[plot_criteria[1]], normalize='columns') * 100,2)).style.background_gradient(cmap = cm)\n",
        "\n",
        "# Distribution of Obesity\n",
        "sns.countplot(df['Obesity'],hue=df['class'], data=df)\n",
        "plot_criteria= ['Obesity', 'class']\n",
        "cm = sns.light_palette(\"red\", as_cmap=True)\n",
        "(round(pd.crosstab(df[plot_criteria[0]], df[plot_criteria[1]], normalize='columns') * 100,2)).style.background_gradient(cmap = cm)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLiLp_c88wg5"
      },
      "source": [
        "#Assigning quantitative values to each categorical variables.\n",
        "df['Gender'] = df['Gender'].map({'Male':1,'Female':0})\n",
        "df['class'] = df['class'].map({'Positive':1,'Negative':0})\n",
        "df['Polyuria'] = df['Polyuria'].map({'Yes':1,'No':0})\n",
        "df['Polydipsia'] = df['Polydipsia'].map({'Yes':1,'No':0})\n",
        "df['sudden weight loss'] = df['sudden weight loss'].map({'Yes':1,'No':0})\n",
        "df['weakness'] = df['weakness'].map({'Yes':1,'No':0})\n",
        "df['Polyphagia'] = df['Polyphagia'].map({'Yes':1,'No':0})\n",
        "df['Genital thrush'] = df['Genital thrush'].map({'Yes':1,'No':0})\n",
        "df['visual blurring'] = df['visual blurring'].map({'Yes':1,'No':0})\n",
        "df['Itching'] = df['Itching'].map({'Yes':1,'No':0})\n",
        "df['Irritability'] = df['Irritability'].map({'Yes':1,'No':0})\n",
        "df['delayed healing'] = df['delayed healing'].map({'Yes':1,'No':0})\n",
        "df['partial paresis'] = df['partial paresis'].map({'Yes':1,'No':0})\n",
        "df['muscle stiffness'] = df['muscle stiffness'].map({'Yes':1,'No':0})\n",
        "df['Alopecia'] = df['Alopecia'].map({'Yes':1,'No':0})\n",
        "df['Obesity'] = df['Obesity'].map({'Yes':1,'No':0})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfgjtznAnz8u"
      },
      "source": [
        "#Computing the correlation and plotting heat map\n",
        "corrdata = round(df.corr(),2)\n",
        "corrdata\n",
        "ax,fig = plt.subplots(figsize=(15,8))\n",
        "sns.heatmap(corrdata, cmap=\"magma\", square=True,linewidth=0.5,linecolor=\"white\" ,cbar=True,annot=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFb-Msku_LlI"
      },
      "source": [
        "#extracting independent variables and dependent variable from data set \n",
        "x1 = df.iloc[:,0:-1]\n",
        "y1 = df.iloc[:,-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT0GKw2lumPt"
      },
      "source": [
        "#For each X, calculat variance  inflation factor(VIF) and save in dataframe\n",
        "vif = pd.DataFrame()\n",
        "vif[\"VIF Factor\"] = [variance_inflation_factor(x1.values, i) for i in range(x1.shape[1])]\n",
        "vif[\"Variables\"] = x1.columns\n",
        "print(vif)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcofdvJc8YH4"
      },
      "source": [
        "#We drop the variable 'age' , as VIF is grater than 5.\n",
        "x1 = df.iloc[:,1:-1]\n",
        "y1 = df.iloc[:,-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69UJwz1bEGoQ"
      },
      "source": [
        "#Feature selection\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "best_feature = SelectKBest(score_func=chi2,k=10)\n",
        "fit = best_feature.fit(x1,y1)\n",
        "\n",
        "dataset_scores = pd.DataFrame(fit.scores_)\n",
        "dataset_cols = pd.DataFrame(x1.columns)\n",
        "featurescores = pd.concat([dataset_cols,dataset_scores],axis=1)\n",
        "featurescores.columns=['Variables','scores']\n",
        "print(featurescores.nlargest(10,'scores'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "um_YMtmORu0T"
      },
      "source": [
        "#Taking top 10 variabes into consideration\n",
        "X = df[['Polydipsia','Polyuria','sudden weight loss','partial paresis','Gender','Irritability','Polyphagia','Alopecia','visual blurring','weakness']]\n",
        "y = df['class']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzhR9CcYSK9L"
      },
      "source": [
        "#Splitting the data into training and testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83OQFEENSVF0"
      },
      "source": [
        "#Standardization of the dataset\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "ss = StandardScaler()\n",
        "X_train = ss.fit_transform(X_train)\n",
        "X_test = ss.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVHNVyGuSjKg"
      },
      "source": [
        "#Logistic regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "lg=LogisticRegression()\n",
        "lg.fit(X_train,y_train)\n",
        "\n",
        "#cross-validation\n",
        "accuracies = cross_val_score(estimator=lg, X=X_train ,y=y_train,cv=10)\n",
        "print(\"accuracy is {:.2f} %\".format(accuracies.mean()*100))\n",
        "print(\"std is {:.2f} %\".format(accuracies.std()*100))\n",
        "\n",
        "#Computing parameteres of Logistic Regression model\n",
        "pred=lg.predict(X_test)\n",
        "print(lg.predict_proba(X_test))\n",
        "print(\"intercept:\",lg.intercept_)\n",
        "print (\"coefficient:\",lg.coef_)\n",
        "\n",
        "#model accuracy\n",
        "logistic_regression=accuracy_score(pred,y_test)\n",
        "print(\"accuracy score:\",accuracy_score(pred,y_test))\n",
        "print(confusion_matrix(pred,y_test))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnxjT8gYwzO5"
      },
      "source": [
        "#K Nearest Neighbor Classifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "knn=KNeighborsClassifier(n_neighbors=3,metric='euclidean',p=2)\n",
        "knn.fit(X_train,y_train)\n",
        "pre=knn.predict(X_test)\n",
        "\n",
        "result= confusion_matrix(y_test,pre)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(result)\n",
        "result1 = classification_report(y_test,pre)\n",
        "print(\"Classification Report:\",)\n",
        "print (result1)\n",
        "result2= accuracy_score(y_test,pre)\n",
        "print(\"Accuracy:\",result2)  \n",
        "no_neighbors = np.arange(1, 15)\n",
        "test_accuracy = np.empty(len(no_neighbors))\n",
        "\n",
        "for i, k in enumerate(no_neighbors):\n",
        "    # We instantiate the classifier\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    # Fit the classifier to the training data\n",
        "    knn.fit(X_train,y_train)\n",
        "    # Compute accuracy on the testing set\n",
        "    test_accuracy[i] = knn.score(X_test, y_test)\n",
        "\n",
        "# Visualization of different k values vs accuracy\n",
        "\n",
        "plt.title('k-NN: Varying Number of Neighbors')\n",
        "plt.plot(no_neighbors, test_accuracy, label = 'Testing Accuracy')\n",
        "plt.legend()\n",
        "plt.xlabel('Number of Neighbors')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvY3wKhvAY6O"
      },
      "source": [
        "#Bernoulli Naive Bayes\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report\n",
        "b=BernoulliNB()\n",
        "b.fit(X_train,y_train)\n",
        "\n",
        "#cross-validation\n",
        "accuracies = cross_val_score(estimator=b, X=X_train ,y=y_train,cv=10)\n",
        "print(\"accuracy is {:.2f} %\".format(accuracies.mean()*100))\n",
        "print(\"std is {:.2f} %\".format(accuracies.std()*100))\n",
        "\n",
        "#accuracy\n",
        "pre4=b.predict(X_test)\n",
        "Naive_bayes_bernoulli_nb=accuracy_score(pre4,y_test)\n",
        "print(accuracy_score(pre4,y_test))\n",
        "print(confusion_matrix(pre4,y_test))\n",
        "print(b.predict_proba(X_test))\n",
        "print(classification_report(pre4,y_test))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA0Pe4f-Eb6b"
      },
      "source": [
        "#For the compartision of all the three techniques , Receiver operating characteristic curve (ROC) is plotted.\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "# Add the models to the list that you want to view on the ROC plot\n",
        "models = [\n",
        "{\n",
        "    'label': 'Logistic Regression',\n",
        "    'model': LogisticRegression(random_state = 0, penalty = 'l2'),\n",
        "},\n",
        "\n",
        "    {\n",
        "    'label': 'K Nearst Neighbors',\n",
        "    'model': KNeighborsClassifier(),\n",
        "},\n",
        "{\n",
        "    'label': 'Bernoulli Naive Bayes',\n",
        "    'model': BernoulliNB()\n",
        "    \n",
        "},  \n",
        "]\n",
        "\n",
        "# Below for loop iterates through your models list\n",
        "for m in models:\n",
        "    model = m['model']\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred=model.predict(X_test)\n",
        "    \n",
        "# Compute False postive rate, and True positive rate\n",
        "    fpr, tpr, thresholds = metrics.roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
        "    \n",
        "# Calculate Area under the curve to display on the plot\n",
        "    auc = metrics.roc_auc_score(y_test,model.predict(X_test))\n",
        "    \n",
        "# Now, plot the computed values\n",
        "    plt.plot(fpr, tpr, label='%s ROC (area = %0.2f)' % (m['label'], auc))\n",
        "    \n",
        "# Custom settings for the plot \n",
        "plt.plot([0, 15], [0, 15],'r--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}